{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/harambe-6/locations/global/keyRings/harambe-6-dev/cryptoKeys/harambe-6-dev-key\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import itertools\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import InputLayer\n",
    "from keras.models import Sequential\n",
    "from sklearn import ensemble\n",
    "\n",
    "import lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_agent(env, num_episodes=500):\n",
    "    q_table = np.zeros((5, 2))\n",
    "    y = 0.95\n",
    "    eps = 0.5\n",
    "    lr = 0.8\n",
    "    decay_factor = 0.999\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        eps *= decay_factor\n",
    "        done = False\n",
    "        while not done:\n",
    "            # print(s)\n",
    "            # print(q_table)\n",
    "            # select the action with highest cummulative reward\n",
    "            if np.random.random() < eps or np.sum(q_table[s, :]) == 0:\n",
    "                a = np.random.randint(0, 2)\n",
    "            else:\n",
    "                a = np.argmax(q_table[s, :])\n",
    "            # pdb.set_trace()\n",
    "            # print(a)\n",
    "            new_s, r, done, _ = env.step(a)\n",
    "            q_table[s, a] += r + lr * (y * np.max(q_table[new_s, :]) - q_table[s, a])\n",
    "            s = new_s\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_agent_keras(env, num_episodes=500):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(batch_input_shape=(1, 5)))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "    y = 0.95\n",
    "    eps = 0.5\n",
    "    decay_factor = 0.999\n",
    "    r_avg_list = []\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        eps *= decay_factor\n",
    "        done = False\n",
    "        r_sum = 0\n",
    "        while not done:\n",
    "            if np.random.random() < eps:\n",
    "                a = np.random.randint(0, 2)\n",
    "            else:\n",
    "                a = np.argmax(model.predict(np.identity(5)[s:s + 1]))\n",
    "            new_s, r, done, _ = env.step(a)\n",
    "            target = r + y * np.max(model.predict(np.identity(5)[new_s:new_s + 1]))\n",
    "            target_vec = model.predict(np.identity(5)[s:s + 1])[0]\n",
    "            target_vec[a] = target\n",
    "            model.fit(np.identity(5)[s:s + 1], target_vec.reshape(-1, 2), epochs=1, verbose=0)\n",
    "            s = new_s\n",
    "            r_sum += r\n",
    "        r_avg_list.append(r_sum / num_episodes)\n",
    "    return r_avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55.71752222 55.87102867]\n",
      " [55.18226486 57.02198783]\n",
      " [67.0745028  56.97468817]\n",
      " [73.20648333 59.37902097]\n",
      " [80.54734582 62.49020854]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"NChain-v0\")\n",
    "print(reward_agent(env, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_env = gym.make(\"NChain-v0\")\n",
    "print(reward_agent_keras(keras_env, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_account(cash=100000):\n",
    "    return {\n",
    "        \"cash\": cash,\n",
    "        \"portfolio\": {}\n",
    "    }\n",
    "\n",
    "\n",
    "def buy_all(account, share_price, symbol):\n",
    "    num_shares = 0 if account[\"cash\"] <= 0 else account[\"cash\"] // share_price\n",
    "    account[\"cash\"] -= num_shares * share_price\n",
    "    account[\"portfolio\"][symbol] = num_shares\n",
    "    return account\n",
    "\n",
    "\n",
    "def short_all(account, share_price, symbol):\n",
    "    num_shares = 0 if account[\"cash\"] <= 0 else account[\"cash\"] // share_price\n",
    "    account[\"cash\"] += num_shares * share_price\n",
    "    account[\"portfolio\"][symbol] = -num_shares\n",
    "    return account\n",
    "\n",
    "\n",
    "def close(account, share_price, symbol):\n",
    "    num_shares = account[\"portfolio\"][symbol]\n",
    "\n",
    "    if num_shares > 0:\n",
    "        # selling\n",
    "        account[\"cash\"] += num_shares * share_price\n",
    "    else:\n",
    "        # buying back short\n",
    "        account[\"cash\"] -= -num_shares * share_price\n",
    "        \n",
    "    account[\"portfolio\"][symbol] = 0\n",
    "    return account\n",
    "\n",
    "def get_account_value(account, current_prices):\n",
    "    value = account[\"cash\"]\n",
    "    \n",
    "    for symbol in account[\"portfolio\"]:\n",
    "        value += account[\"portfolio\"][symbol] * current_prices[symbol]\n",
    "        \n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_action(clf, state, pred_diff, denorm_diff, eps):\n",
    "    if 0 <= state <= 3:\n",
    "        predictions = [clf.predict([[pred_diff, denorm_diff, i]])[0] for i in range(1, 4)]\n",
    "\n",
    "        if random.random() < eps or any(p == 0 for p in predictions):\n",
    "            return random.randint(1, 3)\n",
    "        else:\n",
    "            return predictions.index(max(predictions)) + 1\n",
    "    else:\n",
    "        predictions = [clf.predict([[pred_diff, denorm_diff, i]])[0] for i in range(0, 2)]\n",
    "\n",
    "        if random.random() < eps or any(p == 0 for p in predictions):\n",
    "            return random.randint(0, 1)\n",
    "        else:\n",
    "            return predictions.index(max(predictions))\n",
    "\n",
    "\n",
    "def add_reward(clf, conditions, rewards, pred_diff, denorm_diff, action, reward):\n",
    "    # print(f\"add reward for {action}: {reward}\")\n",
    "    np.append(conditions, [pred_diff, denorm_diff, action])\n",
    "    np.append(rewards, [reward])\n",
    "    return clf.fit(conditions, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_trades(frames, model, action_mapping):\n",
    "    account = init_account()\n",
    "    last_state = 4\n",
    "    # 0 = close, 1 = do nothing, 2 = buy, 3 = short\n",
    "    last_action = 1\n",
    "    last_account_value = get_account_value(account, {})\n",
    "\n",
    "    # clf = ensemble.GradientBoostingRegressor()\n",
    "    # clf.fit(conditions, rewards)\n",
    "\n",
    "    for i, current_frame in enumerate(frames[1:]):\n",
    "        previous_frame = frames[i-1]\n",
    "        \n",
    "        current_normalized_frame = lstm.normalize_frame(current_frame)\n",
    "        previous_normalized_frame = lstm.normalize_frame(previous_frame)\n",
    "    \n",
    "        current_prediction = lstm.predict_sequences_multiple(model, [current_normalized_frame])\n",
    "        previous_prediction = lstm.predict_sequences_multiple(model, [previous_normalized_frame])\n",
    "        \n",
    "        current_prediction_denorm = lstm.denormalize_dim(current_prediction[0][0], current_frame[0][0])\n",
    "        \n",
    "        pred_diff = current_prediction[0][0] - previous_prediction[0][0]\n",
    "\n",
    "        \n",
    "        has_position = \"XYZ\" in account[\"portfolio\"] and account[\"portfolio\"][\"XYZ\"] != 0\n",
    "        # TODO: split coefficient\n",
    "        share_price = float(current_frame[-1][0])\n",
    "        \n",
    "#         if pred_diff > 0 and current_prediction_denorm > share_price:\n",
    "#             if not has_position:\n",
    "#                 print(\"BUY\")\n",
    "#                 account = buy_all(account, share_price, \"XYZ\")\n",
    "#         elif pred_diff < 0 and current_prediction_denorm < share_price:\n",
    "#             if not has_position:\n",
    "#                 print(\"SHORT\")\n",
    "#                 account = short_all(account, share_price, \"XYZ\")\n",
    "#         elif has_position:\n",
    "#             print(\"CLOSING\")\n",
    "#             account = close(account, share_price, \"XYZ\")\n",
    "\n",
    "        if not has_position:\n",
    "            # can only hold, buy, or short\n",
    "            if pred_diff > 0:\n",
    "                if current_prediction_denorm > share_price:\n",
    "                    state = 0\n",
    "                else:\n",
    "                    state = 1\n",
    "            else:\n",
    "                if current_prediction_denorm > share_price:\n",
    "                    state = 2\n",
    "                else:\n",
    "                    state = 3\n",
    "        else:\n",
    "            # can only close or hold\n",
    "            state = 4\n",
    "        \n",
    "        action = action_mapping[state]\n",
    "#         print(state)\n",
    "#         print(action)\n",
    "#         print(reward_table)\n",
    "        \n",
    "        if action == 0:\n",
    "            # close\n",
    "            account = close(account, share_price, \"XYZ\")\n",
    "        elif action == 2:\n",
    "            # buy\n",
    "            account = buy_all(account, share_price, \"XYZ\")\n",
    "        elif action == 3:\n",
    "            # short\n",
    "            account = short_all(account, share_price, \"XYZ\")\n",
    "\n",
    "        # reward = get_account_value(account, {\"XYZ\": share_price}) - last_account_value\n",
    "        # reward += 0.8 * (0.95 * np.max(reward_table[state, :]) - reward_table[last_state, last_action])\n",
    "#         clf = add_reward(\n",
    "#             clf,\n",
    "#             conditions,\n",
    "#             rewards,\n",
    "#             pred_diff,\n",
    "#             current_prediction_denorm - share_price,\n",
    "#             last_action,\n",
    "#             reward\n",
    "#         )\n",
    "\n",
    "        last_state = state\n",
    "        last_action = action\n",
    "        last_account_value = get_account_value(account, {\"XYZ\": share_price})\n",
    "        \n",
    "            \n",
    "    return account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL=\"MSFT\"\n",
    "\n",
    "# get testing data\n",
    "times = lstm.get_time_series_daily(SYMBOL, [\"1. open\"], outputsize=\"full\")\n",
    "vectors = lstm.times_to_vectors(times, include_time=False)[::-1]\n",
    "\n",
    "# TODO: split at dates\n",
    "train_vectors, test_vectors = lstm.partition_data(vectors, partition_coefficient=0.8)\n",
    "\n",
    "train_frames = lstm.get_frames(train_vectors, 15, with_target=True)\n",
    "test_frames = lstm.get_frames(test_vectors, 15, with_target=False)\n",
    "\n",
    "train_no_dates = [[[col for col in vector] for vector in frame] for frame in train_frames]\n",
    "normalized_train = lstm.normalize_frames(train_no_dates)\n",
    "x_train, y_train = lstm.seperate_xy(normalized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.01971912384033203\n",
      "Train on 4055 samples, validate on 214 samples\n",
      "Epoch 1/1\n",
      "4055/4055 [==============================] - 2s 479us/step - loss: 0.9384 - val_loss: 0.7291\n"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "model = lstm.setup_lstm_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 0, 0, 0), (0, 0, 0, 0, 1), (0, 0, 0, 1, 1), (0, 0, 1, 1, 1), (0, 1, 1, 1, 1), (1, 1, 1, 1, 1)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'XYZ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6b7bcc00c510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction_mappings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0maccount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_trades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0maccount_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_account_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"XYZ\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b818e7f60f17>\u001b[0m in \u001b[0;36msimulate_trades\u001b[0;34m(frames, model, action_mapping)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maccount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XYZ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# buy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1845fd461ce6>\u001b[0m in \u001b[0;36mclose\u001b[0;34m(account, share_price, symbol)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnum_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"portfolio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_shares\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'XYZ'"
     ]
    }
   ],
   "source": [
    "num_states = 5\n",
    "num_actions = 4\n",
    "action_mappings = list(\n",
    "    filter(\n",
    "        lambda p: not any(a < 1 for a in p[:4]) and p[4] < 2,\n",
    "        itertools.permutations([i for i in range(num_states)])\n",
    "    )\n",
    ")\n",
    "print(action_mappings)\n",
    "\n",
    "max_mapping = action_mappings[0]\n",
    "max_account_value = 0\n",
    "\n",
    "for mapping in action_mappings:\n",
    "    account = simulate_trades(test_frames, model, mapping)\n",
    "    account_value = get_account_value(account, {\"XYZ\": float(test_frames[-1][-1][0])})\n",
    "    \n",
    "    print(account_value)\n",
    "    \n",
    "    if account_value > max_account_value:\n",
    "        max_account_value = account_value\n",
    "        max_mapping = mapping\n",
    "\n",
    "# print(max_account_value)\n",
    "# print(reward_table)\n",
    "print(max_mapping)\n",
    "print(max_account_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
